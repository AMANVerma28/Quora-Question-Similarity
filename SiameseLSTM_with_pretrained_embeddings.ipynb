{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "198bb4yzYZSM",
    "outputId": "f6ae7207-52ac-488b-d9e4-66beb88f46a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-02-12 06:37:15--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.164.109\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.164.109|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz.1’\n",
      "\n",
      "GoogleNews-vectors- 100%[===================>]   1.53G  70.3MB/s    in 26s     \n",
      "\n",
      "2019-02-12 06:37:41 (60.2 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz.1’ saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download google word2vec pretrained embedding \n",
    "!wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8_bgIrx5QsVK",
    "outputId": "30389ac4-2097-48b0-cd43-1ae40cecdb53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Import Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1DOpgwk6Y3rW",
    "outputId": "d32e1272-4771-4f7c-fa27-edad5c505a9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# !pip install gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3xB94IeiZczQ",
    "outputId": "d60e158c-b4d8-4a74-9453-9749b1e5b877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "TRAIN_CSV = '/content/drive/My Drive/Datasets/quora-question-pairs/train.csv'\n",
    "TEST_CSV = '/content/drive/My Drive/Datasets/quora-question-pairs/test.csv'\n",
    "# TEST1_CSV = '/content/drive/My Drive/Datasets/quora-question-pairs/testquestions/OwnTrainingData.csv'\n",
    "EMBEDDING_FILE = '/content/GoogleNews-vectors-negative300.bin.gz'\n",
    "MODEL_SAVING_DIR = '/content/'\n",
    "LOG_DIR=\"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45RZhFvwZ-EP"
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    ''' \n",
    "    Pre process and convert texts to a list of words \n",
    "    input: str\n",
    "    output: list of cleaned word\n",
    "    '''\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(\"quikly\",\"quickly\", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "_jHMt1zxaUpT",
    "outputId": "fb198e10-94e5-4887-b60b-130c87504b27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14257812, -0.03686523,  0.13574219, -0.06201172,  0.07958984,\n",
       "        0.01904297, -0.08154297, -0.12792969, -0.02954102,  0.23632812],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings\n",
    "\n",
    "vocabulary = {} # key is the word, value is the index\n",
    "inverse_vocabulary = ['<unk>'] # value is the word, index is the index\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# key is the word, value is a 300 dimensional vector for each word\n",
    "\n",
    "word2vec.word_vec(\"test\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "fzeeM6TLOTYM",
    "outputId": "0d6561f1-1356-4274-85ce-264c19644e52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "# Read the train and test data\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "test1_df = pd.read_csv(TEST1_CSV, names=['question1', 'question2', 'is_duplicate'], header=None)\n",
    "train_df.head()\n",
    "print(\"load done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "eRoLPGEwQBgg",
    "outputId": "a67de5d7-7708-4c99-a48e-3f47612afa49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id                                          question1  \\\n",
       "0       0  How does the Surface Pro himself 4 compare wit...   \n",
       "1       1  Should I have a hair transplant at age 24? How...   \n",
       "2       2  What but is the best way to send money from Ch...   \n",
       "3       3                        Which food not emulsifiers?   \n",
       "4       4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 908
    },
    "colab_type": "code",
    "id": "n7pK0JQU0a17",
    "outputId": "f74c1b9d-778a-4259-d2d9-6456eb0b2d17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.2000e+02, 0.0000e+00, 7.9600e+02, 0.0000e+00, 5.1780e+03,\n",
       "        0.0000e+00, 1.3172e+04, 0.0000e+00, 2.6239e+04, 0.0000e+00,\n",
       "        4.2694e+04, 0.0000e+00, 5.3076e+04, 0.0000e+00, 5.2240e+04,\n",
       "        0.0000e+00, 4.4186e+04, 0.0000e+00, 3.4520e+04, 0.0000e+00,\n",
       "        2.6351e+04, 0.0000e+00, 2.0407e+04, 0.0000e+00, 1.5814e+04,\n",
       "        0.0000e+00, 1.2744e+04, 0.0000e+00, 1.1039e+04, 0.0000e+00,\n",
       "        8.7920e+03, 0.0000e+00, 6.7340e+03, 0.0000e+00, 5.1920e+03,\n",
       "        0.0000e+00, 4.3630e+03, 0.0000e+00, 3.6580e+03, 0.0000e+00,\n",
       "        3.1080e+03, 0.0000e+00, 2.7780e+03, 0.0000e+00, 2.3750e+03,\n",
       "        0.0000e+00, 1.8470e+03, 0.0000e+00, 1.6180e+03, 0.0000e+00,\n",
       "        0.0000e+00, 1.2630e+03, 0.0000e+00, 8.3500e+02, 0.0000e+00,\n",
       "        6.2400e+02, 0.0000e+00, 4.4600e+02, 0.0000e+00, 3.4200e+02,\n",
       "        0.0000e+00, 2.7100e+02, 0.0000e+00, 2.2200e+02, 0.0000e+00,\n",
       "        1.6900e+02, 0.0000e+00, 1.6600e+02, 0.0000e+00, 1.3300e+02,\n",
       "        0.0000e+00, 1.0000e+02, 0.0000e+00, 9.2000e+01, 0.0000e+00,\n",
       "        7.2000e+01, 0.0000e+00, 6.0000e+01, 0.0000e+00, 6.2000e+01,\n",
       "        0.0000e+00, 5.4000e+01, 0.0000e+00, 3.8000e+01, 0.0000e+00,\n",
       "        4.0000e+01, 0.0000e+00, 3.3000e+01, 0.0000e+00, 3.5000e+01,\n",
       "        0.0000e+00, 2.2000e+01, 0.0000e+00, 1.5000e+01, 0.0000e+00,\n",
       "        1.5000e+01, 0.0000e+00, 2.7000e+01, 0.0000e+00, 1.1300e+02]),\n",
       " array([ 1.  ,  1.49,  1.98,  2.47,  2.96,  3.45,  3.94,  4.43,  4.92,\n",
       "         5.41,  5.9 ,  6.39,  6.88,  7.37,  7.86,  8.35,  8.84,  9.33,\n",
       "         9.82, 10.31, 10.8 , 11.29, 11.78, 12.27, 12.76, 13.25, 13.74,\n",
       "        14.23, 14.72, 15.21, 15.7 , 16.19, 16.68, 17.17, 17.66, 18.15,\n",
       "        18.64, 19.13, 19.62, 20.11, 20.6 , 21.09, 21.58, 22.07, 22.56,\n",
       "        23.05, 23.54, 24.03, 24.52, 25.01, 25.5 , 25.99, 26.48, 26.97,\n",
       "        27.46, 27.95, 28.44, 28.93, 29.42, 29.91, 30.4 , 30.89, 31.38,\n",
       "        31.87, 32.36, 32.85, 33.34, 33.83, 34.32, 34.81, 35.3 , 35.79,\n",
       "        36.28, 36.77, 37.26, 37.75, 38.24, 38.73, 39.22, 39.71, 40.2 ,\n",
       "        40.69, 41.18, 41.67, 42.16, 42.65, 43.14, 43.63, 44.12, 44.61,\n",
       "        45.1 , 45.59, 46.08, 46.57, 47.06, 47.55, 48.04, 48.53, 49.02,\n",
       "        49.51, 50.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine the distribution of the length of questions \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_df.question1.map(lambda x: len(str(x).split())).values, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "6F7zcpJabBBm",
    "outputId": "648bd92b-46a4-4c89-89b8-a387e4f1baf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "outside_words=set()\n",
    "from tqdm import tqdm\n",
    "questions_cols = ['question1', 'question2']\n",
    "for dataset in [train_df, test_df, test1_df]:\n",
    "  for index,row in (dataset.iterrows()):\n",
    "    for question in questions_cols:\n",
    "      \n",
    "      q2n = [] \n",
    "      count_ = 0\n",
    "      # convert a question to a integer list, the integer corresponding to the index in the small vocabulary\n",
    "      for word in text_to_word_list(row[question]):\n",
    "        \n",
    "        if word not in word2vec.vocab:\n",
    "          outside_words.add(word)\n",
    "          continue\n",
    "          \n",
    "        # limit the length to 50, this decreased the time to train an epoch from more than 1 hour to 20 minutes.\n",
    "        if count_ >= 50 :\n",
    "          continue\n",
    "        count_ +=1\n",
    "        \n",
    "        if word not in vocabulary:\n",
    "          vocabulary[word] = len(inverse_vocabulary)\n",
    "          q2n.append(len(inverse_vocabulary))\n",
    "          inverse_vocabulary.append(word)\n",
    "        else:\n",
    "          q2n.append(vocabulary[word])\n",
    "      \n",
    "      \n",
    "      dataset.set_value(index,question,q2n)\n",
    "\n",
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary)+1, embedding_dim)\n",
    "embeddings[0] = 0\n",
    "# by using the code above, the first vector of embeddings are all 0.\n",
    "embeddings[0]\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "T-UR0-VzbplU",
    "outputId": "282ae5a4-173d-4710-a799-61ef699b0c57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/227 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a17c01acf76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "for word, index in tqdm(vocabulary.items()):\n",
    "  if word in word2vec.vocab:\n",
    "    embeddings[index] = word2vec.word_vec(word)\n",
    "    \n",
    "del word2vec\n",
    "# calculate the max length \n",
    "\n",
    "max_seq_length = max(train_df.question1.map(lambda x:len(x)).max(),\n",
    "                    train_df.question2.map(lambda x:len(x)).max(),\n",
    "                    test_df.question1.map(lambda x:len(x)).max(),\n",
    "                    test_df.question2.map(lambda x:len(x)).max(),\n",
    "                    test1_df.question1.map(lambda x:len(x)).max(),\n",
    "                    test1_df.question2.map(lambda x:len(x)).max())\n",
    "# max_seq_length = 50\n",
    "print(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3jcvR8GuQ-1"
   },
   "outputs": [],
   "source": [
    "num_samples = len(train_df)\n",
    "validation_size = (int)(num_samples * 0.2)\n",
    "training_size = len(train_df) - validation_size \n",
    "questions_cols = ['question1', 'question2']\n",
    "X = train_df[questions_cols]\n",
    "X_test = test_df[questions_cols]\n",
    "# X_test1 = test1_df[questions_cols]\n",
    "Y = train_df['is_duplicate']\n",
    "# Y_test1 = test1_df['is_duplicate']\n",
    "\n",
    "# train test split x and y into train and validation\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X,Y,test_size = validation_size)\n",
    "\n",
    "# Split to dicts\n",
    "X_test = {'left':X_test.question1,'right':X_test.question2}\n",
    "# X_test1 = {'left':X_test1.question1,'right':X_test1.question2}\n",
    "X_train = {'left':X_train.question1,'right':X_train.question2}\n",
    "X_validation = {'left':X_validation.question1,'right':X_validation.question2}\n",
    "#X_test = {'left':X_test.question1,'right':X_test.question2}\n",
    "\n",
    "# fetch Ys\n",
    "Y_train = Y_train.values\n",
    "# Y_test1 = Y_test1.values\n",
    "Y_test = Y_validation.values\n",
    "\n",
    "# zero padding\n",
    "\n",
    "for dataset, side in itertools.product([X_test, X_test1, X_train, X_validation],['left','right']):\n",
    "  dataset[side] = pad_sequences(dataset[side], maxlen = max_seq_length)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "wYhaXSvYEcju",
    "outputId": "066246ba-e3da-45d0-e6ea-4c11d560e85e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 300)      17612100    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50)           70200       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 17,682,300\n",
      "Trainable params: 70,200\n",
      "Non-trainable params: 17,612,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "n_hidden = 50\n",
    "gradient_clipping_norm  = 1.25\n",
    "# what is gradient clipping norm?\n",
    "# https://www.quora.com/What-is-gradient-clipping-and-why-is-it-necessary\n",
    "\n",
    "batch_size = 64\n",
    "n_epoch = 25\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "  return K.exp(-K.sum(K.abs(left-right),axis = 1, keepdims = True))\n",
    "\n",
    "# Input layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype=\"int32\")\n",
    "right_input = Input(shape=(max_seq_length,), dtype=\"int32\")\n",
    "\n",
    "# Embedding layer\n",
    "embedding_layer = Embedding(\n",
    "    input_dim = len(embeddings),\n",
    "    output_dim = embedding_dim, \n",
    "    weights= [embeddings],\n",
    "    input_length=max_seq_length,\n",
    "    trainable=False)\n",
    "\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# LSTM Layer\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculate the Manhattan Distance of the two outputs\n",
    "malstm_distance = Lambda(function = lambda x:exponent_neg_manhattan_distance(x[0],x[1]),\\\n",
    "                         output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "malstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a74RqzhJucly"
   },
   "outputs": [],
   "source": [
    "optimizer = Adadelta(clipnorm = gradient_clipping_norm)\n",
    "# What is Adadelta optimizer?\n",
    "# https://keras.io/optimizers/#adadelta\n",
    "# the advantage of this is we dont need to set a learning-rate for the optimizer. \n",
    "# Adadelta is a more robust extension of Adagrad that adapts learning rates based \n",
    "# on a moving window of gradient updates, instead of accumulating all past gradients.\n",
    "# https://www.quora.com/What-is-gradient-clipping-and-why-is-it-necessary\n",
    "# here, we just need to know, gradient clipping can make the converge faster, it's helpful to limit the gradient to control the exploding of gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-3WZADjT86a"
   },
   "outputs": [],
   "source": [
    "malstm.load_weights('/content/drive/My Drive/Datasets/quora-question-pairs/model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2359
    },
    "colab_type": "code",
    "id": "5ZaXKWQTwwFx",
    "outputId": "c820af28-719e-4f54-d86e-9b6dd8982ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323432 samples, validate on 80858 samples\n",
      "Epoch 1/25\n",
      "323432/323432 [==============================] - 1270s 4ms/step - loss: 0.1808 - acc: 0.7307 - val_loss: 0.1701 - val_acc: 0.7483\n",
      "\n",
      "Epoch 00001: saving model to weights.hdf5\n",
      "Epoch 2/25\n",
      "323432/323432 [==============================] - 1232s 4ms/step - loss: 0.1635 - acc: 0.7665 - val_loss: 0.1608 - val_acc: 0.7742\n",
      "\n",
      "Epoch 00002: saving model to weights.hdf5\n",
      "Epoch 3/25\n",
      "323432/323432 [==============================] - 1217s 4ms/step - loss: 0.1565 - acc: 0.7809 - val_loss: 0.1561 - val_acc: 0.7784\n",
      "\n",
      "Epoch 00003: saving model to weights.hdf5\n",
      "Epoch 4/25\n",
      "323432/323432 [==============================] - 1212s 4ms/step - loss: 0.1519 - acc: 0.7897 - val_loss: 0.1527 - val_acc: 0.7843\n",
      "\n",
      "Epoch 00004: saving model to weights.hdf5\n",
      "Epoch 5/25\n",
      "323432/323432 [==============================] - 1239s 4ms/step - loss: 0.1485 - acc: 0.7953 - val_loss: 0.1507 - val_acc: 0.7928\n",
      "\n",
      "Epoch 00005: saving model to weights.hdf5\n",
      "Epoch 6/25\n",
      "323432/323432 [==============================] - 1343s 4ms/step - loss: 0.1461 - acc: 0.7995 - val_loss: 0.1494 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00006: saving model to weights.hdf5\n",
      "Epoch 7/25\n",
      "323432/323432 [==============================] - 1279s 4ms/step - loss: 0.1440 - acc: 0.8030 - val_loss: 0.1474 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00007: saving model to weights.hdf5\n",
      "Epoch 8/25\n",
      "323432/323432 [==============================] - 1228s 4ms/step - loss: 0.1423 - acc: 0.8059 - val_loss: 0.1463 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00008: saving model to weights.hdf5\n",
      "Epoch 9/25\n",
      "323432/323432 [==============================] - 1224s 4ms/step - loss: 0.1408 - acc: 0.8080 - val_loss: 0.1448 - val_acc: 0.8017\n",
      "\n",
      "Epoch 00009: saving model to weights.hdf5\n",
      "Epoch 10/25\n",
      "323432/323432 [==============================] - 1215s 4ms/step - loss: 0.1396 - acc: 0.8101 - val_loss: 0.1442 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00010: saving model to weights.hdf5\n",
      "Epoch 11/25\n",
      "323432/323432 [==============================] - 1209s 4ms/step - loss: 0.1384 - acc: 0.8117 - val_loss: 0.1428 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00011: saving model to weights.hdf5\n",
      "Epoch 12/25\n",
      "323432/323432 [==============================] - 1264s 4ms/step - loss: 0.1373 - acc: 0.8138 - val_loss: 0.1420 - val_acc: 0.8044\n",
      "\n",
      "Epoch 00012: saving model to weights.hdf5\n",
      "Epoch 13/25\n",
      "323432/323432 [==============================] - 1366s 4ms/step - loss: 0.1363 - acc: 0.8153 - val_loss: 0.1417 - val_acc: 0.8044\n",
      "\n",
      "Epoch 00013: saving model to weights.hdf5\n",
      "Epoch 14/25\n",
      "323432/323432 [==============================] - 1385s 4ms/step - loss: 0.1354 - acc: 0.8169 - val_loss: 0.1408 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00014: saving model to weights.hdf5\n",
      "Epoch 15/25\n",
      "323432/323432 [==============================] - 1381s 4ms/step - loss: 0.1346 - acc: 0.8184 - val_loss: 0.1405 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00015: saving model to weights.hdf5\n",
      "Epoch 16/25\n",
      "323432/323432 [==============================] - 1366s 4ms/step - loss: 0.1338 - acc: 0.8199 - val_loss: 0.1400 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00016: saving model to weights.hdf5\n",
      "Epoch 17/25\n",
      "323432/323432 [==============================] - 1239s 4ms/step - loss: 0.1330 - acc: 0.8214 - val_loss: 0.1394 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00017: saving model to weights.hdf5\n",
      "Epoch 18/25\n",
      "323432/323432 [==============================] - 1267s 4ms/step - loss: 0.1323 - acc: 0.8223 - val_loss: 0.1391 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00018: saving model to weights.hdf5\n",
      "Epoch 19/25\n",
      "323432/323432 [==============================] - 1280s 4ms/step - loss: 0.1316 - acc: 0.8238 - val_loss: 0.1382 - val_acc: 0.8098\n",
      "\n",
      "Epoch 00019: saving model to weights.hdf5\n",
      "Epoch 20/25\n",
      "323432/323432 [==============================] - 1214s 4ms/step - loss: 0.1310 - acc: 0.8250 - val_loss: 0.1380 - val_acc: 0.8095\n",
      "\n",
      "Epoch 00020: saving model to weights.hdf5\n",
      "Epoch 21/25\n",
      "323432/323432 [==============================] - 1151s 4ms/step - loss: 0.1304 - acc: 0.8259 - val_loss: 0.1378 - val_acc: 0.8109\n",
      "\n",
      "Epoch 00021: saving model to weights.hdf5\n",
      "Epoch 22/25\n",
      "323432/323432 [==============================] - 1134s 4ms/step - loss: 0.1298 - acc: 0.8268 - val_loss: 0.1374 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00022: saving model to weights.hdf5\n",
      "Epoch 23/25\n",
      "323432/323432 [==============================] - 1143s 4ms/step - loss: 0.1293 - acc: 0.8278 - val_loss: 0.1371 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00023: saving model to weights.hdf5\n",
      "Epoch 24/25\n",
      "323432/323432 [==============================] - 1143s 4ms/step - loss: 0.1287 - acc: 0.8293 - val_loss: 0.1370 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00024: saving model to weights.hdf5\n",
      "Epoch 25/25\n",
      "323432/323432 [==============================] - 1215s 4ms/step - loss: 0.1283 - acc: 0.8302 - val_loss: 0.1371 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00025: saving model to weights.hdf5\n"
     ]
    },
    {
     "ename": "MessageError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-240ebcee0038>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
     ]
    }
   ],
   "source": [
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=LOG_DIR.format(time()))\n",
    "\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\\\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "LJfIZJ9W-Quo",
    "outputId": "2fbb5674-726c-49e8-87f2-47452c108c77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07441217],\n",
       "       [0.33911413],\n",
       "       [0.4280171 ],\n",
       "       [0.03815874],\n",
       "       [0.702497  ],\n",
       "       [0.02664997],\n",
       "       [0.64101887],\n",
       "       [0.6607826 ],\n",
       "       [0.47963896],\n",
       "       [0.02368323]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "p_test = malstm.predict([X_test['left'][0:10],X_test['right'][0:10]])\n",
    "\n",
    "p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54xP3pWR2gK1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "malstm.save_weights(\"model_weights.h5\")\n",
    "files.download('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsSfsvGjKKjy"
   },
   "outputs": [],
   "source": [
    "files.download('model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Malstm_quoraquestionpair.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

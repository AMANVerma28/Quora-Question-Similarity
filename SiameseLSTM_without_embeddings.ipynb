{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vN8FwRyL9z1V",
    "outputId": "20926d18-74b5-4c91-f3f2-21b6d5eaab6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, LSTM, Embedding, Lambda\n",
    "# from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "G_jsn6cA98Ac",
    "outputId": "3a56d83e-d466-41a8-ee49-3b845f857307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_TA981TQ-RlH",
    "outputId": "ada6c2ea-aebb-4efe-fdf8-bc62686d8135"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/content/drive/My Drive/Datasets/quora-question-pairs/train.csv')\n",
    "df_test = pd.read_csv('/content/drive/My Drive/Datasets/quora-question-pairs/test.csv')\n",
    "# df_test1 = pd.read_csv('/content/drive/My Drive/Datasets/quora-question-pairs/testquestions/OwnTrainingData.csv', \\\n",
    "#                        names=['question1', 'question2', 'is_duplicate'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jQZBbJ_Dpbs"
   },
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    ''' \n",
    "    Pre process and convert texts to a list of words \n",
    "    input: str\n",
    "    output: list of cleaned word\n",
    "    '''\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = re.sub(\"quikly\",\"quickly\", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2uyXF5xyuZ_"
   },
   "outputs": [],
   "source": [
    "list_sentences_train_q1 = df_train[\"question1\"]\n",
    "list_sentences_train_q2 = df_train[\"question2\"]\n",
    "list_sentences_test_q1 = df_test[\"question1\"]\n",
    "list_sentences_test_q2 = df_test[\"question2\"]\n",
    "list_sentences_test1_q1 = df_test1[\"question1\"]\n",
    "list_sentences_test1_q2 = df_test1[\"question2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ivoELSqC-kPf"
   },
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "cleaned_train_q1 = []\n",
    "cleaned_train_q2 = []\n",
    "cleaned_test_q1 = []\n",
    "cleaned_test_q2 = []\n",
    "# cleaned_test1_q1 = []\n",
    "# cleaned_test1_q2 = []\n",
    "\n",
    "for q in list(list_sentences_train_q1):\n",
    "    q_words = text_to_word_list(q)\n",
    "    cleaned_train_q1.append(\" \".join(q_words))\n",
    "    \n",
    "for q in list(list_sentences_train_q2):\n",
    "    q_words = text_to_word_list(q)\n",
    "    cleaned_train_q2.append(\" \".join(q_words))\n",
    "\n",
    "for q in list(list_sentences_test_q1):\n",
    "    q_words = text_to_word_list(q)\n",
    "    cleaned_test_q1.append(\" \".join(q_words))\n",
    "    \n",
    "for q in list(list_sentences_test_q2):\n",
    "    q_words = text_to_word_list(q)\n",
    "    cleaned_test_q2.append(\" \".join(q_words))\n",
    "\n",
    "# for q in list(list_sentences_test1_q1):\n",
    "#     q_words = text_to_word_list(q)\n",
    "#     cleaned_test1_q1.append(\" \".join(q_words))\n",
    "    \n",
    "# for q in list(list_sentences_test1_q2):\n",
    "#     q_words = text_to_word_list(q)\n",
    "#     cleaned_test1_q2.append(\" \".join(q_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xscSu3mwE_aS"
   },
   "outputs": [],
   "source": [
    "del list_sentences_test1_q1\n",
    "del list_sentences_test1_q2\n",
    "del list_sentences_test_q1\n",
    "del list_sentences_test_q2\n",
    "del list_sentences_train_q1\n",
    "del list_sentences_train_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JhORwkxFMGY"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "max_features = 2000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(cleaned_train_q1+cleaned_train_q2)\n",
    "list_tokenized_train_q1 = tokenizer.texts_to_sequences(cleaned_train_q1)\n",
    "list_tokenized_train_q2 = tokenizer.texts_to_sequences(cleaned_train_q2)\n",
    "list_tokenized_test_q1 = tokenizer.texts_to_sequences(cleaned_test_q1)\n",
    "list_tokenized_test_q2 = tokenizer.texts_to_sequences(cleaned_test_q2)\n",
    "list_tokenized_test1_q1 = tokenizer.texts_to_sequences(cleaned_test1_q1)\n",
    "list_tokenized_test1_q2 = tokenizer.texts_to_sequences(cleaned_test1_q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqnGO4bXUlUq"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "maxlen = 25 # Restricting the Maximum length of a question to 25 to reduce the training time from 20 mins to 6-7 mins\n",
    "\n",
    "X = pd.DataFrame({'question1':list(list_tokenized_train_q1), 'question2':list(list_tokenized_train_q2)})\n",
    "Y = df_train[\"is_duplicate\"]\n",
    "X_test = pd.DataFrame({'question1':list(list_tokenized_test_q1), 'question2':list(list_tokenized_test_q2)})\n",
    "# X_test1 = pd.DataFrame({'question1':list(list_tokenized_test1_q1), 'question2':list(list_tokenized_test1_q2)})\n",
    "# Y_test1 = df_test1[\"is_duplicate\"]\n",
    "\n",
    "# train test split x and y into train and validation\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X,Y,test_size = 0.1)\n",
    "\n",
    "# Split to dicts\n",
    "X_test = {'left':X_test.question1,'right':X_test.question2}\n",
    "# X_test1 = {'left':X_test1.question1,'right':X_test1.question2}\n",
    "X_train = {'left':X_train.question1,'right':X_train.question2}\n",
    "X_validation = {'left':X_validation.question1,'right':X_validation.question2}\n",
    "#X_test = {'left':X_test.question1,'right':X_test.question2}\n",
    "\n",
    "# fetch Ys\n",
    "Y_train = Y_train.values\n",
    "# Y_test1 = Y_test1.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "# zero padding\n",
    "for dataset, side in itertools.product([X_test, X_test1, X_train, X_validation],['left','right']):\n",
    "  dataset[side] = pad_sequences(dataset[side], maxlen = maxlen)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "efOoBeFRqalZ",
    "outputId": "2a130b78-09b4-47c7-9c6c-9133b5a5c8e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train['left'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "MK5TrfvY_Shq",
    "outputId": "7e9ac499-50bb-4bb3-e33d-5ffc5f8c8313"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train_q1]\n",
    "plt.hist(totalNumWords, bins = np.arange(0,50,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "2eKucNgI_exs",
    "outputId": "76cc455a-f55a-430d-c8de-1ac5aa7c606f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 128)      256000      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50)           35800       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 291,800\n",
      "Trainable params: 291,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 50\n",
    "gradient_clipping_norm  = 1.25\n",
    "# what is gradient clipping norm?\n",
    "# https://www.quora.com/What-is-gradient-clipping-and-why-is-it-necessary\n",
    "\n",
    "batch_size = 64\n",
    "n_epoch = 25\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "  return K.exp(-K.sum(K.abs(left-right),axis = 1, keepdims = True))\n",
    "\n",
    "# Input layer\n",
    "left_input = Input(shape=(maxlen,), dtype=\"int32\")\n",
    "right_input = Input(shape=(maxlen,), dtype=\"int32\")\n",
    "\n",
    "# Embedding layer\n",
    "# Not using a pretrained Embedding but training the embedding in the model itself\n",
    "embed_size = 128\n",
    "embedding_layer = Embedding(max_features, embed_size)\n",
    "\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# LSTM layer\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "malstm_distance = Lambda(function = lambda x:exponent_neg_manhattan_distance(x[0],x[1]),\\\n",
    "                         output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "malstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s5g8bQAm_nzr"
   },
   "outputs": [],
   "source": [
    "optimizer = Adadelta(clipnorm = gradient_clipping_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "P2x58H4ZAPPD",
    "outputId": "c9fceee1-df07-4bbe-88fb-55bdefa39d4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363861 samples, validate on 40429 samples\n",
      "Epoch 1/5\n",
      "363861/363861 [==============================] - 364s 1ms/step - loss: 0.1403 - acc: 0.8183 - val_loss: 0.1451 - val_acc: 0.8101\n",
      "\n",
      "Epoch 00001: saving model to weights.hdf5\n",
      "Epoch 2/5\n",
      "363861/363861 [==============================] - 363s 998us/step - loss: 0.1396 - acc: 0.8194 - val_loss: 0.1453 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00002: saving model to weights.hdf5\n",
      "Epoch 3/5\n",
      "363861/363861 [==============================] - 364s 1ms/step - loss: 0.1389 - acc: 0.8206 - val_loss: 0.1451 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00003: saving model to weights.hdf5\n",
      "Epoch 4/5\n",
      "363861/363861 [==============================] - 362s 995us/step - loss: 0.1382 - acc: 0.8219 - val_loss: 0.1457 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00004: saving model to weights.hdf5\n",
      "Epoch 5/5\n",
      "363861/363861 [==============================] - 364s 1000us/step - loss: 0.1375 - acc: 0.8232 - val_loss: 0.1455 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00005: saving model to weights.hdf5\n"
     ]
    }
   ],
   "source": [
    "malstm.load_weights('weights.hdf5')\n",
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "filepath=\"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=5,\\\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFSy2FehFLHz"
   },
   "outputs": [],
   "source": [
    "malstm.save_weights(\"weights_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eb-PO_lUFbvQ"
   },
   "outputs": [],
   "source": [
    "malstm.save(\"saved_model_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "Zr-LpyDMG_XV",
    "outputId": "4473dcde-ea22-4ece-88e9-16a70209422d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 128)      256000      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50)           35800       embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 291,800\n",
      "Trainable params: 291,800\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "  return K.exp(-K.sum(K.abs(left-right),axis = 1, keepdims = True))\n",
    "\n",
    "model_v2 = load_model(\"saved_model_v2.h5\", custom_objects={'exponent_neg_manhattan_distance':exponent_neg_manhattan_distance})\n",
    "model_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q0MM6sMOCWf5",
    "outputId": "79143ac6-8611-4fd0-f3cd-40978ace9782"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model_v2.predict([X_validation['left'][:10], X_validation['right'][:10]])\n",
    "y_classes = Y_pred.argmax(axis=-1)\n",
    "y_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVlv5Om6brRW"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# print(accuracy_score(Y_test1, Y_pred))\n",
    "def test_on_example(q1, q2):\n",
    "    cleaned_q1 = []\n",
    "    cleaned_q2 = []\n",
    "    q1 = [q1]\n",
    "    q2 = [q2]\n",
    "    for q in list(q1):\n",
    "        q1_words = text_to_word_list(q)\n",
    "        cleaned_q1.append(\" \".join(q1_words))\n",
    "    \n",
    "    for q in list(q2):\n",
    "        q2_words = text_to_word_list(q)\n",
    "        cleaned_q2.append(\" \".join(q2_words))\n",
    "        \n",
    "    tokenized_q1 = tokenizer.texts_to_sequences(cleaned_q1)\n",
    "    tokenized_q2 = tokenizer.texts_to_sequences(cleaned_q2)\n",
    "    \n",
    "    to_test = pd.DataFrame({'question1':list(tokenized_q1), 'question2':list(tokenized_q2)})\n",
    "    \n",
    "    X_to_test = {'left':to_test.question1,'right':to_test.question2}\n",
    "    # zero padding\n",
    "    for dataset, side in itertools.product([X_to_test],['left','right']):\n",
    "        dataset[side] = pad_sequences(dataset[side], maxlen = maxlen)\n",
    "\n",
    "    score = model_v2.predict([X_to_test[\"left\"], X_to_test[\"right\"]])\n",
    "    for s in score:\n",
    "        if s >= 0.5:\n",
    "            print(\"The sentences are same\\nConfidence = \",\"{:.4f}\".format(s[0]))\n",
    "        else:\n",
    "            print(\"The sentences are different\\nConfidence = \",\"{:.4f}\".format(s[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZROaY9olcatx",
    "outputId": "7e1db6a4-42c8-45fe-f7fc-3c394491a346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentences are same\n",
      "Confidence =  0.8104\n"
     ]
    }
   ],
   "source": [
    "test_on_example(\"How do I read and find my YouTube comments?\",\"How can I see all my Youtube comments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eFFpQJhfHvxq"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "tokenizer_file = open(\"tokenizer\",\"wb\")\n",
    "pickle.dump(tokenizer, tokenizer_file)\n",
    "tokenizer_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0VkdmWfNRrMT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "QuoraQuestionPairs.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
